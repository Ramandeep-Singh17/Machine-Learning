{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy20+jeO9qoGybU0dIdc7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramandeep-Singh17/Machine-Learning/blob/main/14_Unsupervised_learning_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NErMZGupTBda"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  Unsupervised Learning (USL) â€“ Hidden Intelligence ğŸ§©\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” What is Unsupervised Learning?\n",
        "\n",
        "Unsupervised Learning ek aisi Machine Learning technique hai jisme:\n",
        "- **Data ke sath koi label nahi hota**\n",
        "- Model ko **khud patterns aur structure dhoondhne padte hain**\n",
        "- Output pre-defined nahi hota â†’ model khud clusters / groups / rules nikalta hai\n",
        "\n",
        "---\n",
        "\n",
        "## â“ Why do we use Unsupervised Learning?\n",
        "\n",
        "- Jab:\n",
        "  - **Labeling data mushkil ya expensive ho**\n",
        "  - Hume **unknown patterns / insights** discover karne ho\n",
        "  - Hume data ko group ya simplify karna ho\n",
        "\n",
        "ğŸ¯ **Goal**:\n",
        "- Pattern find karna  \n",
        "- Hidden structure samajhna  \n",
        "- Clustering, Dimensionality Reduction, Outlier Detection karna\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ• When to Use?\n",
        "\n",
        "- Jab data me labels available nahi hote  \n",
        "- Jab data high-dimensional ho  \n",
        "- Jab objective sirf pattern samajhna ho, prediction nahi\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒ Where to Use?\n",
        "\n",
        "| Use Case                 | Example                                 |\n",
        "|--------------------------|-----------------------------------------|\n",
        "| ğŸ¦ Bank Fraud Detection  | Outlier Detection                       |\n",
        "| ğŸ›ï¸ Customer Segmentation | Clustering (market analysis)            |\n",
        "| ğŸ“· Image Compression      | Dimensionality Reduction (PCA)          |\n",
        "| ğŸ§ Music Recommendation   | Find user taste clusters                |\n",
        "| ğŸ§¬ Medical Research       | Patient grouping via gene data          |\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ How it Works?\n",
        "\n",
        "1. Input = Unlabeled data  \n",
        "2. Algorithm = Clustering / PCA / DBSCAN / Anomaly Detection  \n",
        "3. Output = Clusters, compressed features, outlier flags  \n",
        "4. No predefined \"right\" answer â†’ just hidden structure discovery\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒŸ Real-Life Examples:\n",
        "\n",
        "| Problem                      | USL Technique        |\n",
        "|------------------------------|----------------------|\n",
        "| Bank Fraud Detection         | Outlier Detection    |\n",
        "| Customer Segmentation        | Clustering (K-Means) |\n",
        "| Image Compression            | PCA                  |\n",
        "| Student Grouping by Behavior | Clustering           |\n",
        "| Noise Removal in Data        | PCA / ICA            |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” Supervised vs Unsupervised Learning\n",
        "\n",
        "| Feature               | Supervised Learning             | Unsupervised Learning                |\n",
        "|-----------------------|----------------------------------|--------------------------------------|\n",
        "| Input                 | Features + Labels                | Only Features                        |\n",
        "| Output                | Predefined (Yes/No, Price)       | Discovered (clusters/patterns)       |\n",
        "| Goal                  | Prediction / Classification      | Pattern Discovery / Grouping         |\n",
        "| Examples              | LR, DT, SVM, KNN                 | K-Means, PCA, DBSCAN, IsolationForest|\n",
        "| Use Cases             | Spam detection, Price prediction | Customer segmentation, Fraud detect  |\n",
        "| From Notes            | Classification / Regression      | Clustering / Dimensionality Reduction|\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© Key Use Goals\n",
        "\n",
        "- âœ”ï¸ Pattern find karna  \n",
        "- âœ”ï¸ Hidden structure identify karna  \n",
        "- âœ”ï¸ Clustering (group similar data)  \n",
        "- âœ”ï¸ Dimensionality Reduction (DR)  \n",
        "- âœ”ï¸ Outlier Detection (fraud detection)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§¬ Types of Unsupervised Learning\n",
        "\n",
        "### 1ï¸âƒ£ Clustering\n",
        "> Similar data points ko group karna (no labels)\n",
        "\n",
        "**Popular Clustering Algorithms:**\n",
        "- ğŸ”¹ K-Means\n",
        "- ğŸ”¹ Hierarchical Clustering\n",
        "- ğŸ”¹ DBSCAN (Density-Based)\n",
        "\n",
        "### 2ï¸âƒ£ Dimensionality Reduction (DR)\n",
        "> High-dimensional data ko kam features me convert karna while preserving structure\n",
        "\n",
        "**Common DR Techniques:**\n",
        "- ğŸ”¸ PCA (Principal Component Analysis)\n",
        "- ğŸ”¸ t-SNE\n",
        "- ğŸ”¸ Autoencoders\n",
        "- ğŸ”¸ ICA (Independent Component Analysis)\n",
        "\n",
        "### 3ï¸âƒ£ Anomaly / Outlier Detection\n",
        "> Unusual ya rare data points identify karna\n",
        "\n",
        "**Popular Techniques:**\n",
        "- ğŸ”º Isolation Forest\n",
        "- ğŸ”º One-Class SVM\n",
        "- ğŸ”º DBSCAN (outlier as noise)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Memory Table (Clean Summary)\n",
        "\n",
        "| Type                     | Sub-Types / Algorithms                   | Goal                               |\n",
        "|--------------------------|------------------------------------------|------------------------------------|\n",
        "| ğŸ”µ Clustering            | K-Means, DBSCAN, Hierarchical            | Group similar points               |\n",
        "| ğŸ”¶ Dimensionality Reduction | PCA, t-SNE, ICA, Autoencoders           | Reduce data dimensions             |\n",
        "| ğŸ”º Outlier Detection     | Isolation Forest, One-Class SVM, DBSCAN  | Detect rare / unusual points       |\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mXWkWXlXXplt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qNZuKSSHXqLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§° Common Techniques in Unsupervised Learning\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ Clustering â€“ Similar Data Points Ko Group Karna\n",
        "\n",
        "### ğŸ“Œ What it does:\n",
        "- Similar data points ko **group** karta hai\n",
        "- Har group = **cluster**\n",
        "- No labels, only data patterns\n",
        "\n",
        "### ğŸ“ˆ Algorithms:\n",
        "- **K-Means**\n",
        "- **Hierarchical Clustering**\n",
        "- **DBSCAN**\n",
        "\n",
        "### ğŸ’¡ Real-Life Examples:\n",
        "- ğŸ›ï¸ Customer Segmentation â†’ Grouping customers by purchase behavior\n",
        "- ğŸ§ Music App â†’ Grouping songs by user listening pattern\n",
        "- ğŸ§¬ Medical â†’ Patient disease pattern clustering\n",
        "\n",
        "---\n",
        "\n",
        "## 2ï¸âƒ£ Dimensionality Reduction (DR)\n",
        "\n",
        "### ğŸ“Œ What it does:\n",
        "- **High-dimensional** data ko **low dimensions** me convert karta hai\n",
        "- Core idea: **important info ko preserve karna**, useless noise hata dena\n",
        "\n",
        "### ğŸ“ˆ Algorithms:\n",
        "- **PCA (Principal Component Analysis)**\n",
        "- **t-SNE (Visualization)**\n",
        "- **ICA (Independent Component Analysis)**\n",
        "- **Autoencoders (Neural Network-based DR)**\n",
        "\n",
        "### ğŸ’¡ Real-Life Examples:\n",
        "- ğŸ“· Image Compression â†’ Reduce size using PCA\n",
        "- ğŸ“Š Visualization â†’ Plot high-dimensional data in 2D/3D using t-SNE\n",
        "- ğŸ§¬ Genomics â†’ Reduce 10,000 gene columns â†’ 100 key signals\n",
        "\n",
        "---\n",
        "\n",
        "## 3ï¸âƒ£ Anomaly Detection / Outlier Detection\n",
        "\n",
        "### ğŸ“Œ What it does:\n",
        "- **Rare / abnormal patterns** detect karta hai\n",
        "- Normal data se **alagalag** hone wale points ko flag karta hai\n",
        "\n",
        "### ğŸ“ˆ Algorithms:\n",
        "- **Isolation Forest**\n",
        "- **One-Class SVM**\n",
        "- **DBSCAN (noise points)**\n",
        "\n",
        "### ğŸ’¡ Real-Life Examples:\n",
        "- ğŸ¦ Fraud Detection â†’ Unusual transaction pattern detect\n",
        "- ğŸŒ Network Security â†’ Intrusion detection system\n",
        "- ğŸ¥ Health â†’ Abnormal heartbeats detection (ECG)\n",
        "\n",
        "---\n",
        "\n",
        "## 4ï¸âƒ£ Association Rule Learning\n",
        "\n",
        "### ğŸ“Œ What it does:\n",
        "- Data ke items ke **co-occurrence** ya association dhoondhta hai\n",
        "\n",
        "### ğŸ“ˆ Algorithm:\n",
        "- **Apriori Algorithm**\n",
        "- **Eclat Algorithm**\n",
        "\n",
        "### ğŸ’¡ Real-Life Examples:\n",
        "- ğŸ›’ Market Basket Analysis â†’ \"Customers who buy bread also buy butter\"\n",
        "- ğŸ“ˆ Cross-Selling â†’ Suggest related products\n",
        "\n",
        "---\n",
        "\n",
        "## 5ï¸âƒ£ Autoencoders â€“ Deep Learning-based DR\n",
        "\n",
        "### ğŸ“Œ What it does:\n",
        "- Data compress karta hai and reconstruct karta hai using neural networks\n",
        "- Use hota hai **dimensionality reduction** ya **noise removal** me\n",
        "\n",
        "### ğŸ’¡ Real-Life Examples:\n",
        "- ğŸ–¼ï¸ Denoising images (remove blur or noise)\n",
        "- ğŸ“„ Document encoding (semantic compression)\n",
        "- ğŸ“¦ Feature compression before supervised learning\n",
        "\n",
        "---\n",
        "\n",
        "## 6ï¸âƒ£ Visualization Techniques\n",
        "\n",
        "### ğŸ“Œ What it does:\n",
        "- High-dimensional data ko **2D/3D** plots me convert karta hai\n",
        "- Human-friendly representation deta hai\n",
        "\n",
        "### ğŸ“ˆ Tools:\n",
        "- **t-SNE**\n",
        "- **UMAP**\n",
        "- **PCA (for visualizing clusters)**\n",
        "\n",
        "### ğŸ’¡ Real-Life Examples:\n",
        "- ğŸ“Š Customer clusters ko visualize karna\n",
        "- ğŸ§¬ Visualizing gene groupings\n",
        "- ğŸ§  AI model behavior ko understand karna\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary Table\n",
        "\n",
        "| Technique              | Purpose                          | Example Use Case                   |\n",
        "|------------------------|----------------------------------|------------------------------------|\n",
        "| Clustering             | Group similar data points        | Customer segmentation              |\n",
        "| Dimensionality Reduction | Reduce features, remove noise   | Image compression, gene signals    |\n",
        "| Anomaly Detection      | Find unusual points              | Fraud detection, health anomalies  |\n",
        "| Association Rules      | Discover item relationships      | Market basket analysis             |\n",
        "| Autoencoders           | Neural DR / noise removal        | Denoising images, compress text    |\n",
        "| Visualization          | Visualize high-dim data          | Cluster plots, model explanation   |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9vp7RFeTZNxV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DFiupUvPZRKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  Clustering â€“ Grouping Similar Data (Unsupervised Learning)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” What is Clustering?\n",
        "\n",
        "**Clustering** ek Unsupervised Learning technique hai jisme:\n",
        "- Similar data points ko ek group (cluster) me divide kiya jaata hai  \n",
        "- Labels nahi hote â†’ model khud patterns find karta hai  \n",
        "- Har cluster me items **internally similar** hote hain aur **dusre clusters se different**\n",
        "\n",
        "---\n",
        "\n",
        "## â“ Why Do We Use Clustering?\n",
        "\n",
        "- Jab hume:\n",
        "  - Large unlabeled data me hidden patterns dhoondhne ho\n",
        "  - Similar user types ya behavior samajhna ho\n",
        "  - Natural groups banane ho for better decision making\n",
        "\n",
        "ğŸ¯ Goal: **Find structure & pattern without any supervision**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ• When Do We Use Clustering?\n",
        "\n",
        "- Jab:\n",
        "  - Data unlabeled ho\n",
        "  - Groups pehle se defined na ho\n",
        "  - Hum **exploratory data analysis** (EDA) kar rahe ho\n",
        "  - Market segmentation / recommendation / grouping chahiye ho\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒ Where Do We Use Clustering?\n",
        "\n",
        "| Use Case                  | Example                                        |\n",
        "|---------------------------|------------------------------------------------|\n",
        "| ğŸ›ï¸ Marketing              | Customer segmentation (grouping by behavior)   |\n",
        "| ğŸ§¬ Medical Research        | Grouping diseases/patients by symptom pattern |\n",
        "| ğŸ§ Music App              | Grouping songs by genre similarity             |\n",
        "| ğŸ“· Image Compression      | Divide similar pixels â†’ compress               |\n",
        "| ğŸ§  Social Media Analysis  | Group similar posts/users                      |\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ How Clustering Works?\n",
        "\n",
        "### Steps:\n",
        "1. Input data bina labels ke diya jaata hai\n",
        "2. Algorithm **data points ke similarity** ko check karta hai\n",
        "3. Based on distance (e.g., Euclidean), points ko groups me divide karta hai\n",
        "4. Final output = Multiple clusters jisme similar items grouped hote hain\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¤” Why is it called â€œClusteringâ€?\n",
        "\n",
        "- Kyunki:\n",
        "  - Data points **naturally ek jagah grouped hote hain**\n",
        "  - Alag-alag clusters visually bhi **clearly separated** dikhte hain\n",
        "  - Jaise human eye bhi easily **dekh sakti hai** ki kaunsa point kis cluster me belong karta hai (check diagramğŸ‘‡)\n",
        "\n",
        "  \n",
        "  ## ğŸ“› Clustering Ke Naam Ka Reason\n",
        "\n",
        "- Data apne-aap naturally **clusters (groups)** banata hai\n",
        "- In groups ke andar:\n",
        "  - Data points ek dusre ke **kaafi close / similar** hote hain\n",
        "  - Aur doosre clusters se clearly **alag / distant**\n",
        "- In clusters ko hum **naked eye se bhi easily identify** kar sakte hain (e.g., scatter plot)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒŸ Real-Life Examples of Clustering\n",
        "\n",
        "| ğŸ§ª Scenario               | ğŸ§© Cluster Meaning                            |\n",
        "|--------------------------|-----------------------------------------------|\n",
        "| ğŸ¦ Bank Customers         | Grouped by spending behavior                 |\n",
        "| ğŸ›’ E-commerce Users       | Grouped by product preferences               |\n",
        "| ğŸ“· Image Pixels           | Grouped by similar pixel colors              |\n",
        "| ğŸ§  Psychological Testing  | Grouped by thinking patterns                 |\n",
        "| ğŸ“ Education Analytics    | Grouped by learning styles\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§Š Diagram (ASCII Style - 2D Visualization)\n",
        "\n",
        "```text\n",
        "       Cluster 1        Cluster 2         Cluster 3\n",
        "        â–“â–“â–“â–“â–“             â–‘â–‘â–‘â–‘â–‘              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
        "       â–“     â–“           â–‘     â–‘            â–ˆ     â–ˆ\n",
        "      â–“       â–“         â–‘       â–‘          â–ˆ       â–ˆ\n",
        "       â–“     â–“           â–‘     â–‘            â–ˆ     â–ˆ\n",
        "        â–“â–“â–“â–“â–“             â–‘â–‘â–‘â–‘â–‘              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
        "\n",
        "       (Tightly grouped â†’ visually separable)\n",
        "\n"
      ],
      "metadata": {
        "id": "8KHZGj2iaw0c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPLMnHEzaxwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¹ Types of Clustering Algorithms\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 1. K-Means Clustering\n",
        "\n",
        "- **Centroid-based** method\n",
        "- Points are assigned to the cluster with the nearest **mean (centroid)**\n",
        "- Works well for **numeric & continuous data**\n",
        "- Fast & scalable, but sensitive to outliers\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 2. K-Medoids Clustering (PAM)\n",
        "\n",
        "- Similar to K-Means but uses **medoid** (most central data point) instead of mean\n",
        "- More **robust to outliers**\n",
        "- Works better for small datasets or when data has noise\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 3. K-Modes Clustering\n",
        "\n",
        "- Used for **categorical data**\n",
        "- Uses **mode (most frequent value)** instead of mean\n",
        "- Distance is calculated using **Hamming distance**\n",
        "- Useful for clustering strings or categories\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 4. Hierarchical Clustering\n",
        "\n",
        "- Builds a **tree of clusters** (dendrogram)\n",
        "- Two types:\n",
        "  - **Agglomerative (Bottom-Up)**\n",
        "  - **Divisive (Top-Down)**\n",
        "- Doesnâ€™t require pre-deciding number of clusters\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 5. DBSCAN (Density-Based Spatial Clustering)\n",
        "\n",
        "- Clusters based on **density of data points**\n",
        "- Can find **arbitrary shaped clusters**\n",
        "- Automatically detects **outliers/noise**\n",
        "- Good for **non-spherical** clusters\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 6. Mean Shift Clustering\n",
        "\n",
        "- Moves data points toward **high-density regions**\n",
        "- Doesnâ€™t require K value\n",
        "- Good for detecting **blobs** in image processing\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 7. Gaussian Mixture Model (GMM)\n",
        "\n",
        "- **Probabilistic model** using multiple Gaussians\n",
        "- One point can belong to **multiple clusters** with probability\n",
        "- Useful when clusters **overlap**\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 8. Spectral Clustering\n",
        "\n",
        "- Uses **graph theory** and eigenvalues of similarity matrix\n",
        "- Good for **non-convex or complex shapes**\n",
        "- Performs well with small-medium datasets\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… 9. BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)\n",
        "\n",
        "- Efficient for **very large datasets**\n",
        "- Uses **clustering features tree (CF Tree)** for scalable clustering\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Summary Table\n",
        "\n",
        "| Algorithm         | Data Type       | Shape         | K Needed? | Outlier Robust | Speed  |\n",
        "|------------------|------------------|---------------|-----------|----------------|--------|\n",
        "| K-Means           | Numeric           | Spherical     | âœ… Yes     | âŒ No           | âš¡ Fast |\n",
        "| K-Medoids         | Numeric/Mixed     | Any           | âœ… Yes     | âœ… Yes          | ğŸ¢ Slow |\n",
        "| K-Modes           | Categorical       | N/A           | âœ… Yes     | âœ… Yes          | âš¡ Fast |\n",
        "| Hierarchical      | Any               | Any           | âŒ No      | âŒ Partial      | ğŸ¢ Slow |\n",
        "| DBSCAN            | Any               | Arbitrary     | âŒ No      | âœ… Yes          | âš¡ Fast |\n",
        "| Mean Shift        | Any               | Any           | âŒ No      | âœ… Yes          | ğŸ¢ Slow |\n",
        "| GMM               | Numeric           | Overlapping   | âœ… Yes     | âŒ No           | âš¡ Fast |\n",
        "| Spectral          | Any               | Complex       | âœ… Yes     | âŒ No           | âš¡ Mid  |\n",
        "| BIRCH             | Large datasets    | Hierarchical  | âœ… Yes     | âœ… Yes          | âš¡ Fast |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "0dZgu17Gu3xb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJB_RtKEu3ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“ K-Means Clustering â€“ Grouping with Geometry ğŸ¯\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” What is K-Means Clustering?\n",
        "\n",
        "**K-Means** ek **unsupervised machine learning** algorithm hai jo:\n",
        "- Similar data points ko **K clusters** me divide karta hai  \n",
        "- Har cluster ka ek **center point (centroid)** hota hai  \n",
        "- Algorithm data points ko nearest centroid ke according assign karta hai\n",
        "\n",
        "---\n",
        "\n",
        "## â“ Why Use K-Means?\n",
        "\n",
        "- Jab hume:\n",
        "  - Data me **natural groups** dhoondhne ho\n",
        "  - Labeled data na ho\n",
        "  - Clustering fast aur scalable way me karni ho\n",
        "\n",
        "ğŸ¯ Goal: Similar data points ko ek group me daalna based on **distance from center**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ• When to Use K-Means?\n",
        "\n",
        "- Jab:\n",
        "  - Hume large dataset ko **unsupervised way me group** karna ho\n",
        "  - Hume cluster banana ho but labels na mile\n",
        "  - Fast aur easy clustering chahiye\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒ Where to Use K-Means?\n",
        "\n",
        "| Use Case                | Cluster Meaning                              |\n",
        "|-------------------------|-----------------------------------------------|\n",
        "| ğŸ¦ Customer Segmentation | Alag-alag type ke customer group karna       |\n",
        "| ğŸ“· Image Compression     | Similar color pixels cluster karna           |\n",
        "| ğŸ§  Behavioral Segmentation | Users ko behavior ke base pe group karna    |\n",
        "| ğŸ“ Geo-Location Data     | Cities/stores ko area-wise group karna       |\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ How K-Means Works? â€“ Step by Step ğŸ’¡\n",
        "\n",
        "### ğŸ”¢ Step 1: Decide K (Number of Clusters)\n",
        "- Pehle decide karo **kitne clusters** chahiye (K)\n",
        "- Ye data ka nature ya **Elbow Method** se decide kiya ja sakta hai\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ Step 2: Initialize Centroids\n",
        "- Randomly **K points** ko initial **centroids** banate hain\n",
        "- ğŸ“Œ **Centroid** = Cluster ka center (mean position of all points)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ Step 3: Assign Each Data Point to Nearest Centroid\n",
        "- Har point ka **Euclidean distance** sabhi centroids se calculate hota hai:\n",
        "  (\n",
        "Euclidean Distance = âˆš[(x2 - x1)Â² + (y2 - y1)Â²])\n",
        "\n",
        "  Jis centroid se distance minimum ho â†’ wohi cluster assign hota hai\n",
        "\n",
        "  ## ğŸ”„ Step 4: Recalculate New Centroid\n",
        "\n",
        "- Har cluster ke sabhi points ka **average (mean)** nikalte hain  \n",
        "- Ye average point hi **cluster ka naya centroid** banta hai\n",
        "\n",
        "---\n",
        "\n",
        "## â™»ï¸ Step 5: Reassign Points Based on New Centroids\n",
        "\n",
        "- Ab sabhi points ka **distance naye centroids** se dobara calculate kiya jata hai  \n",
        "- Har point ko **closest centroid ke cluster** me reassign karte hain\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” Step 6: Repeat Until Convergence\n",
        "\n",
        "- Ye process tab tak **repeat** hoti hai jab tak:\n",
        "  - Points ka cluster **change hona band** ho jaye\n",
        "  - Clusters **stable** ho jayein\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Step 7: Final Clusters Achieved\n",
        "\n",
        "- Jab clusters **finalize** ho jaate hain, algorithm **stop** kar deta hai  \n",
        "- Final clusters ka use kiya jata hai:\n",
        "\n",
        "| ğŸ’¡ Use Case           | ğŸ“Œ Purpose                      |\n",
        "|-----------------------|---------------------------------|\n",
        "| ğŸ“ˆ Visualization       | Cluster plots draw karne ke liye |\n",
        "| ğŸ“Š Grouping            | Natural grouping of data        |\n",
        "| ğŸ“¦ Feature Engineering | New features banane ke liye     |\n",
        "| ğŸ” Recommendation      | User/item similarity find karne ke liye |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š Elbow Method â€“ Best K Choose Karne Ke Liye\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“Œ What is Elbow Method?\n",
        "\n",
        "**Elbow Method** ek technique hai jisme:\n",
        "- Multiple values of **K (clusters)** ke liye model banaya jaata hai\n",
        "- Har K ke liye calculate karte hain:\n",
        "\n",
        "> **WCSS = Within-Cluster Sum of Squares**\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“‰ WCSS Explained:\n",
        "\n",
        "> WCSS = Har data point ka apne centroid se **distance squared ka sum**\n",
        "\n",
        "âœ… **Low WCSS** â†’ Clusters are **tight and compact**  \n",
        "â— **Zyada clusters** â†’ WCSS automatically kam ho jaata hai (overfitting risk)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’ª Elbow Curve Logic:\n",
        "\n",
        "- Jab **K increase** karte hain â†’ WCSS continuously decrease hota hai\n",
        "- Ek point aata hai jahan graph **suddenly flat** ho jaata hai  \n",
        "- ğŸ“ Isi point ko kehte hain **\"Elbow Point\"**\n",
        "\n",
        "ğŸ§  **Elbow Point = Optimal K value**  \n",
        "ğŸ‘‰ Jahan tak WCSS sharply girta hai, uske baad flat ho jata hai\n",
        "\n",
        "ğŸ§  Real-Life Examples of K-Means:\n",
        "Area\tUse Case\n",
        "ğŸª Retail\tCustomer segmentation for marketing\n",
        "ğŸ–¼ï¸ Image Processing\tCompress images by clustering pixels\n",
        "ğŸ§¬ Biology\tGrouping similar DNA sequences\n",
        "ğŸ“ Maps / Geo Data\tGrouping cities/stores area-wise\n",
        "ğŸ§  Education\tGrouping students by learning style\n",
        "\n",
        "---\n",
        "\n",
        "            Cluster 1            Cluster 2           Cluster 3\n",
        "              ğŸ”´                     ğŸ”·                   ğŸŸ¢\n",
        "           â—  â—  â—               â—  â—  â—              â—  â—  â—\n",
        "           â— ğŸ”´ â—               â— ğŸ”· â—              â— ğŸŸ¢ â—\n",
        "           â—  â—  â—               â—  â—  â—              â—  â—  â—\n",
        "\n",
        "   (Each color = different cluster; center = centroid)\n",
        "\n",
        "ğŸ“‰ Elbow Curve Example:\n",
        "\n",
        "        |\n",
        "     WCSS|\n",
        "        |\\\n",
        "        | \\\n",
        "        |  \\\n",
        "        |   \\\n",
        "        |    \\______\n",
        "        |          |\n",
        "        |__________|_____________\n",
        "                  K (no. of clusters)\n",
        "                 (elbow point)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sdYUaYU5ssUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âŒ Disadvantages of K-Means Clustering\n",
        "\n",
        "---\n",
        "\n",
        "## 1. â— Must Predefine K\n",
        "\n",
        "- Pehle se hi **clusters ki count (K)** decide karni padti hai  \n",
        "- Galat K value â†’ **incorrect clustering**\n",
        "\n",
        "---\n",
        "\n",
        "## 2. âŒ Sensitive to Initial Centroids\n",
        "\n",
        "- Agar starting centroids **poorly choose** kiye gaye  \n",
        "  â†’ algorithm **wrong clusters** detect kar sakta hai\n",
        "\n",
        "---\n",
        "\n",
        "## 3. ğŸ” Can Converge to Local Minima\n",
        "\n",
        "- K-Means **local minima** me fas sakta hai  \n",
        "- Har bar **same result** nahi deta (due to random init)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. ğŸ”¥ âŒ **Fails on Circular / Irregular Cluster Shapes**\n",
        "\n",
        "- K-Means **sirf spherical (round) clusters** ke liye kaam karta hai  \n",
        "- **Non-circular / complex shapes** (e.g., moons, spirals) me **bad results** deta hai  \n",
        "- Aise cases me **DBSCAN** ya **Spectral Clustering** better hote hain\n",
        "\n",
        "ğŸ“Œ Example: Moon-shaped ya concentric circular clusters = âŒ Not handled well by K-Means\n",
        "\n",
        "---\n",
        "\n",
        "## 5. ğŸ¯ Only Works with Numeric Data\n",
        "\n",
        "- Sirf **numerical/continuous** features ke saath kaam karta hai  \n",
        "- **Categorical data** ke liye suitable nahi (K-Modes better hai)\n",
        "\n",
        "---\n",
        "\n",
        "## 6. âŒ Not Robust to Outliers\n",
        "\n",
        "- **Outliers** centroids ko **distort** kar dete hain  \n",
        "- Poor clustering ho sakta hai\n",
        "\n",
        "---\n",
        "\n",
        "## 7. âš ï¸ Unequal Cluster Sizes\n",
        "\n",
        "- Agar clusters ka size **unequal** hai (e.g., ek bada, ek chhota)\n",
        "  â†’ K-Means **bias** show karta hai\n",
        "\n",
        "---\n",
        "\n",
        "## 8. â›” Non-Convex Clusters = Bad Fit\n",
        "\n",
        "- Complex patterns (e.g., C-shape, spiral) ko K-Means nahi samajh pata  \n",
        "- Algorithm **incorrect boundaries** draw karta hai\n",
        "\n",
        "---\n",
        "\n",
        "ğŸ“Œ In short:\n",
        "\n",
        "| Limitation                 | Impact                                       |\n",
        "|----------------------------|----------------------------------------------|\n",
        "| Predefined K               | Needs domain knowledge                      |\n",
        "| Random Init                | Unstable results                             |\n",
        "| Numeric-only               | Categorical data not handled                |\n",
        "| Outliers                   | Bad centroids & cluster assignment          |\n",
        "| ğŸ”¥ Non-circular Clusters   | Fails on complex cluster shapes             |\n",
        "\n",
        "---\n",
        "\n",
        "ğŸ“‰ Use K-Means only when:\n",
        "- Data is **numeric**\n",
        "- Clusters are **roughly equal & spherical**\n",
        "- Outliers are **handled/removed**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "54aPmMqv1F22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#kmean centroid based hai and iske disadvantage ko overcome karne ke liye hm DBSCAN ka use karte hai"
      ],
      "metadata": {
        "id": "MBMciGvIuhR3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NurrrTtS1jxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“Œ DBSCAN â€“ Density-Based Spatial Clustering of Applications with Noise\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” What is DBSCAN?\n",
        "\n",
        "**DBSCAN** ek **unsupervised clustering algorithm** hai jo:\n",
        "- Data points ko **density ke base pe clusters** me group karta hai\n",
        "- Low-density points ko **outliers/noise** treat karta hai\n",
        "- Full form: **Density-Based Spatial Clustering of Applications with Noise**\n",
        "\n",
        "---\n",
        "\n",
        "## â“ Why Use DBSCAN?\n",
        "\n",
        "- **No need to specify K** (number of clusters) â†’ âŒ No pre-defined clusters\n",
        "- Can handle **arbitrary shape clusters** (circular, moon-shape, etc.)\n",
        "- Automatically detects **outliers/noise**\n",
        "- Works well on **spatial/geographical data**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  DBSCAN is Non-Parametric\n",
        "\n",
        "- **Non-parametric** ka matlab: Isme **model parameters ko fix karna zaroori nahi**\n",
        "- Doesnâ€™t assume data is distributed in any fixed shape (e.g., spherical)\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ How DBSCAN Works? â€“ Step-by-Step ğŸ”„\n",
        "\n",
        "### ğŸ”¹ Step 1: Choose 2 Parameters\n",
        "- **Epsilon (Îµ)** â†’ Radius of the neighborhood (distance threshold)\n",
        "- **MinPts** â†’ Minimum number of points needed in Îµ-radius to form a cluster\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ Step 2: Epsilon Circle (Îµ-Neighbor Concept)\n",
        "\n",
        "- Har point ke around **Îµ distance ka imaginary circle** draw karte hain\n",
        "- Jitne points us circle ke andar aate hain, unhe check karte hain:\n",
        "\n",
        "(\n",
        "Imagine:\n",
        "\n",
        "  (P) â†’ Current point\n",
        "\n",
        "  Radius = Îµ = 1 unit\n",
        "\n",
        "  Points inside this Îµ-circle â†’ Neighboring points)\n",
        "\n",
        "\n",
        " # ğŸ” Step-by-Step: DBSCAN Clustering (Density-Based Spatial Clustering of Applications with Noise)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ Step 3: Classify Points\n",
        "\n",
        "DBSCAN har point ko 3 categories me divide karta hai:\n",
        "\n",
        "| ğŸ§  Point Type    | âœ… Condition                                     | ğŸ“Œ Meaning               |\n",
        "|------------------|--------------------------------------------------|--------------------------|\n",
        "| âœ… Core Point     | Îµ-radius me **MinPts ya zyada points** ho        | Cluster ka center point |\n",
        "| ğŸŸ¡ Border Point   | Îµ-radius me **MinPts se kam**, but cluster ka hissa ho | Edge point           |\n",
        "| âŒ Noise Point    | Na core, na border â†’ **outlier**                | Cluster ke bahar ka point |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ” Step 4: Cluster Expansion\n",
        "\n",
        "- Clustering **core point se start hota hai**\n",
        "- Uske neighbors ko **recursively explore** kiya jata hai\n",
        "- Jab tak naye core points milte hain â†’ cluster **expand** hota rehta hai\n",
        "\n",
        "ğŸ“Œ Cluster tab tak grow karta hai jab tak naye dense regions milte rahein\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  Importance of Epsilon (Îµ)\n",
        "\n",
        "| Condition               | Result                                 |\n",
        "|-------------------------|----------------------------------------|\n",
        "| Îµ **bahut chhota**       | Zyada points **noise ban** jaate hain   |\n",
        "| Îµ **bahut bada**         | Clusters **merge ho** jaate hain       |\n",
        "\n",
        "âœ… Isiliye Îµ ko carefully tune karna hota hai  \n",
        "ğŸ“‰ Usually **k-distance graph** se best Îµ decide kiya jata hai (similar to elbow method)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸŒ Where to Use DBSCAN?\n",
        "\n",
        "| ğŸŒ Domain         | ğŸ“Œ Use Case                                     |\n",
        "|-------------------|-------------------------------------------------|\n",
        "| ğŸ“ Geolocation     | Cluster locations (e.g., delivery points)       |\n",
        "| ğŸŒŒ Astronomy       | Find star clusters or galaxies                  |\n",
        "| ğŸ¦ Banking         | Detect fraud/outlier transactions              |\n",
        "| ğŸ“ Education       | Unusual student behavior detect karna          |\n",
        "| ğŸ§  Psychology      | Cluster similar thought/behavior patterns       |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ• When to Use DBSCAN?\n",
        "\n",
        "Use DBSCAN when:\n",
        "- âœ… Cluster ki shape **irregular / non-spherical** ho\n",
        "- âœ… **Outliers detect** karne ho\n",
        "- âœ… Clusters ka count (K) **define nahi karna ho**\n",
        "\n",
        "---\n",
        "### âœ… Real-Life Examples of DBSCAN\n",
        "\n",
        "| ğŸ—‚ï¸ Area              | ğŸ” Example Use Case                              |\n",
        "|----------------------|--------------------------------------------------|\n",
        "| ğŸ—ºï¸ Maps              | Group GPS locations (delivery clusters)         |\n",
        "| ğŸ§ª Bioinformatics    | Group similar gene/DNA sequences                 |\n",
        "| ğŸ¦ Credit/Fraud      | Detect credit card fraud transactions           |\n",
        "| ğŸŒŒ Astronomy         | Cluster stars or galaxies                        |\n",
        "| ğŸš— Traffic Analytics | Detect accident-prone zones                      |\n",
        "\n",
        "---\n",
        "\n",
        "### âš ï¸ Important Notes\n",
        "\n",
        "- âœ… **Recommended**: `MinPts â‰¥ dimensions + 1`\n",
        "- ğŸ“‰ Use **k-distance graph** to choose best Îµ (epsilon)\n",
        "- âš ï¸ DBSCAN **struggles** when clusters have **very different densities**\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  Summary Table â€“ DBSCAN Power ğŸ’ª\n",
        "\n",
        "| âš™ï¸ Feature             | âœ… DBSCAN Advantage                          |\n",
        "|------------------------|----------------------------------------------|\n",
        "| âŒ No K Required        | Doesnâ€™t need predefined number of clusters   |\n",
        "| âœ… Arbitrary Shapes     | Works on circular, moon, spiral clusters     |\n",
        "| âœ… Outlier Detection    | Automatically identifies noise               |\n",
        "| âœ… Non-Parametric       | No shape/distribution assumption needed      |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1MCQ4HRq3_Nc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "prymRaad5EAo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}